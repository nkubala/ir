<base href="http://www.cs.utexas.edu/~inderjit/courses/dm2009/">
<HTML>
<HEAD>
  <TITLE>Data Mining: A Mathematical Perspective (Fall 2009)</TITLE>
</HEAD>
<BODY BGCOLOR="#eec090" TEXT="black">
<CENTER>

<P ALIGN=CENTER>
<h2>Data Mining: A Mathematical Perspective</h2>
<h2>CS 391D/CAM 395T</h2>
<h3> CS Unique No. 54950 / CAM Unique No. 66117 </h3>
<!-- <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/announce"> <h3> Course Announcement </h3> </a> -->
</CENTER>

Fall 2009 <BR>
TTh 9:30-11am <BR>
WEL 2.312 <br> <br>

Instructor: <a href="http://www.cs.utexas.edu/users/inderjit">Prof. Inderjit Dhillon</a>
    (<a href="mailto:inderjit@cs.utexas.edu">send email</a>) <BR>
Office: ACES 2.332 <br>
Office Hours: Tue 11am-noon  and by appointment<br>
TA: <a href="http://www.cs.utexas.edu/~wtang">Wei Tang</a>
    (<a href="mailto:wtang@cs.utexas.edu">send email</a>) <BR>
Office: TAY 137 <br>
Office Hours: MW 3:30-5:30pm

<h3> Course Description </h3>
<p>
Data mining is the automated discovery of interesting patterns and
relationships in massive data sets.
This graduate course will focus on various mathematical and statistical
aspects of data mining. Topics covered include supervised methods
(regression, classification) and unsupervised
methods (clustering, principal components analysis, dimensionality
reduction). The technical tools used in the course will draw from linear
algebra, multivariate statistics and optimization.
The main tools from these areas will be covered
in class, but undergraduate level linear algebra is a pre-requisite (see below).
A substantial portion of the course will focus on research
projects, where students will choose a well defined research problem.
Projects can vary in their theoretical/mathematical
content, and in the implementation/programming involved.
Projects will be conducted by teams of 2-3 students.
<br> <br>

Pre-requisites: Basics (undergraduate level) of linear algebra (M341 or equivalent) and some mathematical sophistication.
</p>

<h3> Books </h3>
<menu>
<li> "Pattern Recognition and Machine Learning" by C. Bishop, Springer, 2006.
<li> "Elements of Statistical Learning: Data Mining, Inference, and Prediction" by T. Hastie, R. Tibshirani, J. Friedman, Springer-Verlag, 2001.
<li> "Pattern Classification" by R. Duda, P. Hart and D. Stork, John Wiley and Sons, 2000.
</menu>

<h3> Reading Material </h3>
<menu>
<li> <a href="http://www.mathworks.com/academia/student_center/tutorials/launchpad.html">Matlab Tutorials</a>
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/LinearAlgebraBackground.pdf">Linear Algebra Background</a>
<!-- <li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/cs378_lecture2.pdf">Vector-Space Model, SVD and LSI</a> -->
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/Lectures/">Class Lectures</a>
<li> Berkeley slides on <a href="http://www.cs.berkeley.edu/~asimma/294-fall06/lectures/dimension/index.html">Linear Dimensionality Reduction</a> and <a href="http://www.cs.berkeley.edu/~asimma/294-fall06/lectures/nldr.pdf">Non-Linear Dimensionality Reduction</a>
</menu>

<h3> Homeworks </h3>
<menu>
<li> Hard-copies of your homework solutions should be submitted in class on the due date.
<!-- <li> <b>Late Homework Policy:</b> The latest time by which homework solutions can be submitted is 5pm the day after the due date (in the TA's office). Penalty for late submission: 25% penalty till 11am the day after the due date, and 50% penalty for submission after that.</a> -->
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/hw1.pdf">Homework 1</a>, <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/hw1sol.pdf">Solutions</a>.
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/hw2.pdf">Homework 2</a>, <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/hw2sol.pdf">Solutions</a>.
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/hw3.pdf">Homework 3</a>, <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/hw3sol.pdf">Solutions</a>.
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/hw4.pdf">Homework 4</a> <!--, <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/hw4sol.pdf">Solutions</a>. -->
</menu>

<h3>Class Presentations</h3>
<menu>
<li> <a href ="http://www.cs.utexas.edu/users/wtang/cs391d/schedule.html">Schedule</a>
<li> <a href ="http://www.cs.utexas.edu/users/wtang/cs391d/readings.html">Suggestions for Paper Readings</a>
</menu>

<a href ="http://www.cs.utexas.edu/~wtang/cs391d/projects/projectpage.html"> <h3>Class Projects</h3></a>
<menu>
<li> <a href ="http://www.cs.utexas.edu/users/wtang/cs391d/projects/suggestions.html">Project Suggestions</a>
</menu>

<!-- <h3> Syllabus </h3>
<menu>
<li> Overview of Supervised Learning
<li> Linear Methods for Regression
<li> Linear Methods for Classification
<li> Kernel Methods
<li> Model Assessment and Selection
<li> Support Vector Machines
<li> Prototype Methods and Nearest-Neighbors
<li> Unsupervised Learning
</menu> -->

<!-- <h3> Lecture Notes </h3>
<menu>
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2007/lecture1.ps"> Lecture 1</a> - Finding good "hubs" and "authorities" for broad-topic queries.
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2007/lecture2.ps"> Lecture 2</a> - Review of basic linear algebra (vectors, norms, eigenvalues/eigenvectors, SVD), Proof that hub and authority vectors converge to the dominant singular vectors.
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2007/lecture3.ps"> Lectures 3 & 4</a> - HITS, Clever Project, Google's PageRank.</li>
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2007/lecture5.ps">Lectures 5 & 6</a></b> - Vector Space Model, Latent Semantic Indexing, SVD.</li>
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2007/lecture7.ps">Lectures 7, 8 & 9</a></b> - PCA, Clustering, Hierarchical Agglomerative Clustering(HAC), k-means.</li>
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2007/lecture10.ps">Lecture 10</a></b> - Information Theory, Clustering and Bregman Divergences.</li>
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2007/lecture11.ps">Lecture 11</a></b> - Graph partitioning algorithms (Kernighan-Lin, Spectral Partitioning, Multilevel methods such as <a href="http://www-users.cs.umn.edu/~karypis/metis/">Metis</a>.</li>
</menu> -->

<h3> Grading </h3>
<menu>
<li> 10 + 30 = 40% Class Project (First submission + Final submission)
<li> 20%  Homeworks
<li> 25%  Midterm
<li> 10%  Class presentation of a research paper or book chapter/section
<li> 5%   Class participation and attendance
</menu>

<!-- <h3> Handouts </h3>
<menu>
<li> <a href="http://www.cs.utexas.edu/users/inderjit/courses/dm2009/survey.html">Class Survey</a>
</menu> -->

<h3> <a href="http://www.cs.utexas.edu/academics/conduct/">Code of Conduct </a> </h3>

</BODY>
</HTML>
